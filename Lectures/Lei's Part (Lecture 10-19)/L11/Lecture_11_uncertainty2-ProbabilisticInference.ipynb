{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5d0fbc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def hide_code_in_slideshow():   \n",
    "    from IPython import display\n",
    "    import binascii\n",
    "    import os\n",
    "    uid = binascii.hexlify(os.urandom(8)).decode()    \n",
    "    html = \"\"\"<div id=\"%s\"></div>\n",
    "    <script type=\"text/javascript\">\n",
    "        $(function(){\n",
    "            var p = $(\"#%s\");\n",
    "            if (p.length==0) return;\n",
    "            while (!p.hasClass(\"cell\")) {\n",
    "                p=p.parent();\n",
    "                if (p.prop(\"tagName\") ==\"body\") return;\n",
    "            }\n",
    "            var cell = p;\n",
    "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
    "        });\n",
    "    </script>\"\"\" % (uid, uid)\n",
    "    display.display_html(html, raw=True)\n",
    "#  a hack to hide code from cell: https://github.com/damianavila/RISE/issues/32    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab557735",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n    display: None ! important;\n}\n</style>\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ccd2dd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d7080",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS5010 Artificial Intelligence Principles\n",
    "### Lecture 11 Uncertainty 2\n",
    "#### Probabilistic Inference \n",
    "\n",
    "Lei Fang\n",
    "\n",
    "University of St Andrews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eefd83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Last time\n",
    "\n",
    "\n",
    "* Random variable and its distribution\n",
    "\n",
    "$$P(X) >0\\;\\;  \\text{and} \\;\\;\\sum_x P(X=x)=1$$\n",
    "\n",
    "* We can have multiple random variables and their joint distribution (still a distribution)\n",
    "\n",
    "$$P(X_1, X_2, \\ldots, X_n) >0\\;\\;  \\text{and}\\\\ \\;\\;\\sum_{x_1}\\sum_{x_2} \\ldots \\sum_{x_n} P(X_1=x_1, X_2=x_2, \\ldots, X_n=x_n)=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4f42a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Two rules \n",
    "\n",
    "Sum rule: $$P(X=x) = \\sum_{y} P(X=x, Y=y);$$\n",
    "\n",
    "Product rule: $$P(X, Y) = P(X) P(Y|X) = P(Y)P(X|Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba50290",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conditional probability \n",
    "\n",
    "Based on the product rule, we have \n",
    "\n",
    "$$P(X|Y) = \\frac{P(X, Y)}{P(Y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5be59a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This time\n",
    "\n",
    "* Probabilistic inference using joint distribution and the two rules\n",
    "* Baye's rule\n",
    "* Examples of probabilistic inference\n",
    "  * Concept learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d56fe7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probabilistic inference by joint distribution\n",
    "\n",
    "Given two coins with different probabilities of head turning up: \n",
    "  * Coin 1 is a fair coin $p= 0.5$\n",
    "  * Coin 2 is bent with $p=0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74c3be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Your friend randomly pick one coin (which you do not know) and toss it 2 times and record the results, $$Y_1 \\in \\{head,tail\\},\\;\\; Y_2\\in \\{head, tail\\}.$$ \n",
    "\n",
    "Was the fair coin used or not given the following observations?\n",
    "  * $Y_1=h, Y_2=h$\n",
    "  * $Y_1=t, Y_2=t$\n",
    "  * $Y_1=t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e69440",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 1, figure out the random variables \n",
    "\n",
    "\n",
    "Firstly, identify the random variables $$C,\\; Y_1,\\; Y_2$$ \n",
    "  * $C= 1,2$ denote which coin has been used \n",
    "  * $Y_1, Y_2$ are the tossing outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f7b91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2, figure out the joint distribution\n",
    "\n",
    "The joint distrution $P(C, Y_1, Y_2)$ is over $2\\times 2\\times 2$ possible combinations\n",
    "e.g $P(C=1, Y_1 =head, Y_2=head)$ \n",
    "<center><img src=\"https://leo.host.cs.st-andrews.ac.uk/figs/threedbox.png\" width = \"600\" height=\"600\"/></center>\n",
    "  \n",
    "  * We need to specify the $2\\times 2\\times 2$ entries  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae541de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Due to product rule, we have\n",
    "  $$P(C=c, Y_1=y_1, Y_2=y_2) = P(C=c)P(Y_1=y_1, Y_2=y_2|C=c)$$\n",
    "  * As the two tosses are independent, we have \n",
    "  $$P(Y_1, Y_2|C=c)= P(Y_1|C=c)P(Y_2|C=c)$$\n",
    "    * it is called **conditional independence**: condition on knowing the coin choise, the two tosses are independent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac969ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * then we can populate the joint distribution table e.g. $$P(C=1, Y_1=t, Y_2=t) = P(C=1) \\times P(Y_1=t|C=1)\\times P(Y_2=t|C=1) = 0.5 *0.5*0.5$$ $$\\vdots$$ $$P(C=2, Y_1=h, Y_2=h) = P(C=2) \\times P(Y_1=h|C=2)\\times P(Y_2=h|C=2) = 0.5 * 0.2 * 0.2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab8486",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can equivalently represent the 3-dimensional-shaped distribution as a big table (similar to truth table)\n",
    "\n",
    "|C    | Y1  | Y2 | P |\n",
    "| --- | --- |  --- | --- |\n",
    "| 1   | tail   | tail     |  0.125  |\n",
    "| 1   | head   | tail     |  0.125  |\n",
    "| 1   | tail   | head     |  0.125  |\n",
    "| 1   | head   | head     |  0.125  |\n",
    "| 2  | tail   | tail     |  0.32  |\n",
    "| 2   | head   | tail     |  0.08  |\n",
    "| 2   | tail   | head     |  0.08  |\n",
    "| 2   | head   | head     |  0.02  |\n",
    "\n",
    "Note that the sum is one as expected $$\\sum_{c, y_1, y_2} P(\\cdot, \\cdot, \\cdot) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6bd72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step three, probabilistic inference by using the joint distribution\n",
    "Essentially, we want to figure out $$P(C=1|Y_1=y_1, Y_2=y_2)$$\n",
    "  * the distribution of some **unknown** $C$ given evidence $Y_1, Y_2$\n",
    "  * we can simply use probability rules\n",
    "  $$P(C=c|Y_1=y_1, Y_2=y_2) = \\frac{P(C=c, Y_1=y_1, Y_2=y_2)}{P(Y_1=y_1, Y_2=y_2)} = \\frac{P(C=c, Y_1=y_1, Y_2=y_2)}{\\sum_{c} P(C=c, Y_1=y_1, Y_2=y_2)}$$\n",
    "  \n",
    "  |C    | Y1  | Y2 | P |\n",
    "| --- | --- |  --- | --- |\n",
    "| 1   | tail   | tail     |  0.125  |\n",
    "| 1   | head   | tail     |  0.125  |\n",
    "| 1   | tail   | head     |  0.125  |\n",
    "| 1   | head   | head     |  0.125  |\n",
    "| 2  | tail   | tail     |  0.32  |\n",
    "| 2   | head   | tail     |  0.08  |\n",
    "| 2   | tail   | head     |  0.08  |\n",
    "| 2   | head   | head     |  0.02  |\n",
    "\n",
    "  * e.g. $$P(C=1|Y_1= h, Y_2=h) = \\frac{P(C=1, Y_1=h, Y_2=h)}{\\sum_{c=1,2} P(C=c, Y_1=h, Y_2=h)} = \\frac{0.125}{0.125+0.02} = 0.862$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f9437",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  |C    | Y1  | Y2 | P |\n",
    "| --- | --- |  --- | --- |\n",
    "| 1   | tail   | tail     |  0.125  |\n",
    "| 1   | head   | tail     |  0.125  |\n",
    "| 1   | tail   | head     |  0.125  |\n",
    "| 1   | head   | head     |  0.125  |\n",
    "| 2  | tail   | tail     |  0.32  |\n",
    "| 2   | head   | tail     |  0.08  |\n",
    "| 2   | tail   | head     |  0.08  |\n",
    "| 2   | head   | head     |  0.02  |\n",
    " \n",
    "\n",
    "Similarly,\n",
    "if $Y_1=t, Y_2=h$\n",
    "  $$P(C=1|Y_1= t, Y_2=h) = \\frac{P(C=1, Y_1=t, Y_2=h)}{\\sum_{c=1,2} P(C=c, Y_1=t, Y_2=h)} = \\frac{0.125}{0.125+0.08} = 0.61$$\n",
    "  \n",
    "if $Y_1=t, Y_2=t$\n",
    "  $$P(C=1|Y_1= t, Y_2=t) = \\frac{P(C=1, Y_1=t, Y_2=t)}{\\sum_{c=1,2} P(C=c, Y_1=t, Y_2=t)} = \\frac{0.125}{0.125+0.32} = 0.281$$\n",
    "  \n",
    "* Very reasonable, if more Tails are observed, your friend is more likely to have used the bent coin (second coin) or cheating "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281a5ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Joint distribution contains all the information one needs\n",
    "\n",
    "You can calculate **everything** based on the joint distribution\n",
    "\n",
    "For example, we can predict the second toss based on the first toss\n",
    "\n",
    "$$P(Y_2|Y_1) = \\frac{P(Y_1, Y_2)}{P(Y_1)} = \\frac{\\sum_{c} P(C=c, Y_1, Y_2)}{\\sum_{c}\\sum_{y_2}  P(C=c, Y_1, Y_2=y_2)}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8c57a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "e.g. $$P(Y_2=h|Y_1=t) = \\frac{P(Y_1=t, Y_2=h)}{P(Y_1=t)} = \\frac{\\sum_{c} P(C=c, Y_1=t, Y_2=h)}{\\sum_{c}\\sum_{y_2}  P(C=c, Y_1=h, Y_2=y_2)} = \\frac{0.125+0.08}{0.125+0.125+0.32+0.08}=0.315$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701630a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that \n",
    "$$P(Y_2=t|Y_1=t) =  \\frac{\\sum_{c} P(C=c, Y_1=t, Y_2=t)}{\\sum_{c}\\sum_{y_2}  P(C=c, Y_1=h, Y_2=y_2)} = \\frac{0.125+0.32}{0.125+0.125+0.32+0.08}=1- P(Y_2=h|Y_1=t)$$\n",
    "  * $P(Y_2|Y_1=t)$: conditional distribution is a distribution $\\sum P(Y_2|Y_1=t) =1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa990ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also calculate marginal probability on the second toss only\n",
    "\n",
    "$$P(Y_2) = \\sum_{c}\\sum_{y_1} P(C=c, Y_1=y_1, Y_2)$$ e.g. $$P(Y_2=h) = 0.125+0.125+0.08+0.02=0.35$$\n",
    "\n",
    "Again it is easy to verify $$P(Y_2=t) = 1-0.35=0.65$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f5e02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional Independence \n",
    "\n",
    "For the above example, we made the conditional independence assumption: i.e. knowing the coin in use, the tosses become independent: $$P(Y_1, Y_2|C) = P(Y_1|C)(Y_2|C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce035d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that marginally, or without the condition, the two tosses are not independent ! $$P(Y_1, Y_2) \\neq P(Y_1)P(Y_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7813c3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * knowing the result of the first toss $Y_1$ changes our belief on the coin used \n",
    "    * if $Y_1 = t$, then we are more likely to have used the bent coin rather than the fair one\n",
    "    * therefore, the chance to observe another Tail would be increased!\n",
    "    * $P(Y_2=t|Y_1=t) > P(Y_2=t)$\n",
    "    \n",
    "We have verified it already in previous slides\n",
    "$$P(Y_2=t|Y_1=t)=1-P(Y_2=h|Y_1=t)=0.685,  \\;\\; P(Y_2=t) =0.65$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9e87a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Equivalently, conditional independence can be writen as $$P(Y_1 |C, Y_2) = P(Y_1|C)\\;\\; \\text{or} \\;\\; P(Y_2 |C, Y_1)= P(Y_2|C)$$ \n",
    "  * knowing $Y_2$ does not provide any more information if $C$ is known \n",
    "  * can you also prove it from the normal CI definition $P(Y_1, Y_2|C) = P(Y_1|C)(Y_2|C)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3e329",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem with joint distribution\n",
    "\n",
    "* Joint distribution contains all the information but not efficient\n",
    "\n",
    "* Its size increases **exponentially** with respect to the size of random variables\n",
    "\n",
    "* Suppose your friend toss a random chosen coin 5 times \n",
    "  * The random variables are $C, Y_1, Y_2, \\ldots, Y_5$\n",
    "  * $P(C, Y_1, Y_2, \\ldots, Y_5)$ has $2\\times 2 \\times 2 \\times 2 \\times 2 \\times 2$ rows !\n",
    "  * What if toss $20$ times ? 2 million entries! \n",
    "  \n",
    "* Baye's rule comes to rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762f0e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Baye's rule\n",
    "\n",
    "Baye's rule provides an alternative way to do probabilistic inference\n",
    "\n",
    "$$P(Y|X) = \\frac{P(Y)P(X|Y)}{\\sum_{y} P(Y=y)P(X|Y=y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613c084",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Nothing new, just manipulation of the two rules and conditional probability \n",
    "\n",
    "* remember conditional probability\n",
    "\n",
    "$$P(Y|X) = \\frac{P(X, Y)}{P(X)}$$\n",
    "* the **numerator** has used chain rule: $P(Y)P(X|Y) = P(X, Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f881602",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * the **denumerator** has used both summation and chain rule: $P(X) = \\sum_y P(X, Y=y) = \\sum_{y} P(Y=y)P(X|Y=y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20039ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One often writes  \n",
    "\n",
    "$$\\underbrace{P(Y|X)}_{Posterior} \\propto \\underbrace{P(Y)}_{\\text{Prior}}\\underbrace{P(X|Y)}_{\\text{Likelihood}} \\;\\; \\text{or} \\;\\; \\underbrace{P(Y|X)}_{Posterior} = \\alpha \\underbrace{P(Y)}_{\\text{Prior}}\\underbrace{P(X|Y)}_{\\text{Likelihood}}$$\n",
    "  * $\\propto$ means proportional to\n",
    "  * because $P(X)=\\sum_{y} P(Y=y)P(X|Y=y)$ is a normalising constant \n",
    "  * i.e. from $Y=y$'s perspective, it is a constant (written as $\\alpha$); indeed it does not depend on $y$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384be4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probabilistic inference: by Baye's rule\n",
    "\n",
    "Again two coins, one fair the other bent with $p_1= 0.5$ and $p_2=0.2$, \n",
    "\n",
    "Your friend randomly pick one then toss 5 times and made the following observations\n",
    "\n",
    "$$Y_1 = t, Y_2=h, Y_3=t, Y_4=t, Y_5= t$$\n",
    "\n",
    "Which coin he/she has used ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7ec24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "According to Baye's rule,\n",
    "\n",
    "$$\\begin{align}P(C|Y_1, Y_2, Y_3, Y_4, Y_5) &\\propto P(C)P(Y_1, Y_2, Y_3, Y_4, Y_5|C) \\\\\n",
    "&= P(C) \\underbrace{\\prod_{i=1}^5 P(Y_i|C)}_{\\text{Conditional Independence!}}\\end{align}$$\n",
    "\n",
    "\n",
    "So $$P(C=1|t,h,t,t,t) \\propto p(C=1)\\times (1-p_1)p_1(1-p_1)(1-p_1)(1-p_1) = 0.5\\cdot 0.5^5 = 0.0156$$\n",
    "$$P(C=2|t,h,t,t,t) \\propto p(C=2)\\times (1-p_2)p_2(1-p_2)(1-p_2)(1-p_2) = 0.5\\cdot 0.2^1 \\cdot 0.8^4= 0.04096$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6660291",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Normalise (conditional distribution is a distribution, therefore sum to one), i.e. find $\\alpha$\n",
    "\n",
    "$$P(C=1|t,h,t,t,t) = \\frac{0.5\\cdot 0.5^5}{0.5^6 + 0.5\\cdot 0.2\\cdot 0.8^4} = 0.276$$ and \n",
    "\n",
    "$$P(C=2|t,h,t,t,t) = \\frac{0.5\\cdot 0.2\\cdot 0.8^4}{0.5^6 + 0.5\\cdot 0.2\\cdot 0.8^4} = 0.724$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3a5f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The computation scales easily to larger case, say 20 observations $Y_1,\\ldots, Y_{20}$\n",
    "  * where there are 10 heads and 10 tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6ea936",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# a method to calculate the posterior probability of C given the model parameters and observation\n",
    "def calculatePosterior(pc1, p1, p2, nheads, ntails):\n",
    "    posteriors1 = pc1 * p1**nheads * (1-p1)**ntails\n",
    "    posteriors2 = (1-pc1) * p2**nheads * (1-p2)**ntails\n",
    "    return posteriors1/(posteriors1+posteriors2), posteriors2/(posteriors1+posteriors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6790bce3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-bf1bfa02de50>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mnheads\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mntails\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"P(C=1|...)\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"P(C=2|...)\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mcalculatePosterior\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnheads\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mntails\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m;\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "nheads = 10 \n",
    "ntails = 10\n",
    "plt.bar([\"P(C=1|...)\", \"P(C=2|...)\"] , calculatePosterior(0.5, 0.5, 0.2, nheads, ntails))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788ec8e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * what if there are 5 heads and 15 tails ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443e5719",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nheads = 5; ntails = 15;\n",
    "plt.bar([\"P(C=1|...)\", \"P(C=2|...)\"] , calculatePosterior(0.5, 0.5, 0.2, nheads, ntails)); plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7652af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probabilistic inference $P(Query|Evidence)$\n",
    "\n",
    "Probabilistic inference in a nutshell: $P(Query|Evidence)$\n",
    "\n",
    "\n",
    "For example, $P(C|Y_1 = h, Y_2 =h)$\n",
    "* Query: $\\{C\\}$: coin choice\n",
    "* Evidence: $\\{Y_1, Y_2\\}$, i.e. both tosses are heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd1201",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inference with **nuiance** or **hidden** r.v.: $P(Y_2|Y_1 = h)$\n",
    "* Query:s $\\{Y_2\\}$\n",
    "* Evidence: $\\{Y_1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f0530a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Nuisance**, or **hidden** r.v. $\\{C\\}$, all the other r.v. except $Query$ and $Evidence$ : $\\{C, Y_1, Y_2\\}/\\{Y_1, Y_2\\}$\n",
    "* we need to use sum rule to sum them out (so called nuiance r.v.)\n",
    "$$\\begin{align}P(Y_2|Y_1) &= \\sum_c P(Y_2, C=c|Y_1) = \\sum_c P(Y_2|C=c, Y_1) P(C=c|Y_1) \\\\\n",
    "&= \\sum_c \\underbrace{P(Y_2|C=c)}_{\\text{CI assumption!}} P(C=c|Y_1)\\end{align}$$\n",
    "* it makes perfect sense: to make prediction, we need to consider both possible but hidden coin choices and weight them accordingly (the weights are $P(C|Y_1)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070c655",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to specify the probability model\n",
    "\n",
    "The probability model $P(X_1, X_2, \\ldots, X_n)$ can be specified by either\n",
    "\n",
    "1. fully specify the joint distribution: **not practical** in real world applications\n",
    "  * need $O(2^n)$ number of rows or entries (assuming all r.v. are binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2c357",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. or simplied by making conditional independence assumption\n",
    "  * CI usually encodes some causal relations\n",
    "  * e.g. given knowing the coin of choice, the tosses are independent\n",
    "  $$P(C, Y_1, Y_2, \\ldots)= P(C) \\prod P(Y_i|C)$$\n",
    "    * we only need 3 parameters for this example rather than ($2^n-1$); namely $P(C),P(Y_i|C=1), P(Y_i|C=2)$ \n",
    "    * note that we only need one parameter for each distribution as the outcome is binary and the sum needs to be one e.g. $P(C=2) = 1- P(C=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e21394",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More examples of inference and applying Baye's rule\n",
    "\n",
    "A classic example of applying Baye's rule: \n",
    "\n",
    "You are tested positive for COVID by rapid antigen test, with an sensitity of $79\\%$ (some call it accuracy) and specificity $98\\%$. Assume you live in the UK, how likely you are really infected with COVID? \n",
    "  * *sensitivity*: the probability of detecting the disease when there is one\n",
    "  * _specificity_: \"how well does it detect the absence of disease\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2265b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Firstly, identify the random variables, \n",
    "  * $T = \\{0, 1\\}$: testing result is negative (0) or positive (1)\n",
    "  * $C = \\{0, 1\\}$: you are truely infected by COVID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad3000",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Secondly, specify the model $P(C, T)$, essentially to decide which way to apply chain rule \n",
    "\n",
    "$$P(C,T) = P(C)P(T|C)\\;\\; \\text{or} \\;\\; P(C,T)= P(T)P(C|T)$$\n",
    "  1. Consider the \"generating process\"; we need the the causal relationship, obviously\n",
    "  $$C \\Rightarrow T$$ i.e. a test result depends on whether you got the disease or not, and we know \n",
    "  $$P(T=1|C=1) = 0.79$$\n",
    "    * *sensitivity*: the probability of detecting the disease when there is one\n",
    "  $$P(T=0|C=0) = 0.98$$ \n",
    "    * _specificity_: \"how well does it detect the absence of disease\"\n",
    " \n",
    "  2. then $P(C, T) = P(C)P(T|C)$, we still need to specify the prior $P(C)$\n",
    "    * $P(C=1) = 0.02$: the prior probability that a person is infected with COVID in UK\n",
    "      * I used the currect active case number (1.33 million)/the total UK population (67.22 millon) (https://www.worldometers.info/coronavirus/country/uk/)\n",
    "      * or random pick one from the UK now, the chance he has COVID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232485c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lastly, do the inference, we are interested in the posterior $$P(C|T=1)$$\n",
    "\n",
    "  * Apply Baye's rule\n",
    "\n",
    "$$P(C=0|T=1) \\propto P(C=0)P(T=1|C=0)= (1-0.02) * (1-0.98) = 0.0196,\\;\\; \\\\\n",
    "P(C=1|T=1) \\propto P(C=1)P(T=1|C=1)= 0.02 * 0.79 = 0.0158$$\n",
    "  * $P(C|T=1) = \\begin{cases}\\frac{0.0196}{0.0196+0.0158} = 55.4\\%, & C=0 \\\\ \\frac{0.0158}{0.0196+0.0158} =44.6\\%, & C=1 \\end{cases}$\n",
    "  \n",
    "  \n",
    "So you only have $44.6\\%$ chance to really infected with COVID given a positive rapid test result.\n",
    "\n",
    "That's why you usually will be given another confirming PCR (lab) test (gold standard) to confirm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1d2ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exercise: how likely you are infected after a confirming PCR positive result ? \n",
    "What if the confirming result is negative ? \n",
    "\n",
    "Assume a PCR test has sensitivity of 90\\% and specificity of 99.8\\%.\n",
    "\n",
    "  * what r.v.s are there ?\n",
    "  * any conditional independence assumption you can make ?\n",
    "  * what are the parameters ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3dab0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian concept learning\n",
    "\n",
    "An interesting example of applying **Bayesian inference** to replicate human's **concept learning** process. \n",
    "\n",
    "Human are good at summarising or learning concepts from examples. Suppose, you are given a bunch of numbers between 1 and 100:\n",
    "\n",
    "* if the data are $\\{2,4,6,8,10\\}$,  you may deduce the _concept_ is **even numbers**, \n",
    "  * then you may predict the next observation is $12 \\ldots$\n",
    "* if the data are $\\{15, 20, 25\\}$, you may deduce the _concept_ is **multiples of 5**,\n",
    "  * then you may predict the next is e.g. $50$\n",
    "* if the data is $\\{16\\}$, you may deduce the _concept_ is **power of 4** or **multiples of 4** or **even** number\n",
    "  * so you may predict the next is again $64$ or maybe $20, 24$ or $18,\\ldots$.\n",
    "  * not likely you would predict e.g. 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394b095",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prediction made by human (averaged over 8 humans)\n",
    "\n",
    "<center><img src=\"https://leo.host.cs.st-andrews.ac.uk/figs/josh-5-5.png\" width = \"1200\" height=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916a64a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The question: can we **train** a machine to **learn the concepts** and **make predictions** like humans ?\n",
    "  * i.e. feed observations to a machine, ask the machine learn the **concept** correctly ?\n",
    "  * it turns out machine can learn concept well by using a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571700e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Probabilistic model for concept learning\n",
    "\n",
    "We adopt a simple model on the following r.v. $H$ and $\\mathcal{D}$\n",
    "  * $H$: hypothesis or concepts\n",
    "    * e.g. $h_{\\text{two}} \\triangleq \\text{\"power of two\"}$, $h_{\\text{even}} \\triangleq \\text{\"even numbers\"}$\n",
    "    * so $h \\in \\{h_{\\text{even}}, h_{\\text{odd}}, h_{\\text{square}}, h_{\\text{two}}, h_{\\text{three}}, h_{\\text{all}}, \\ldots\\}$\n",
    "  * $\\mathcal{D}$ is the observations, say $\\mathcal{D} = \\{16, 2, 8\\}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb458a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to specify the joint distribution: $P(H, \\mathcal{D})$\n",
    "1. specify P by chain rule: $P(H, \\mathcal{D}) = P(H) P(\\mathcal{D}|H)$\n",
    "  * causal relationship: $H \\Rightarrow \\mathcal{D}$\n",
    "  * easier than the other way around \n",
    "2. assume conditional independent assumption over $\\mathcal{D}$ given $h$, i.e.\n",
    "$$P(\\mathcal{D}|h) = P(d_1, d_2, \\ldots, d_N|h)= \\prod_{i=1}^N P(d_i|h)$$\n",
    "  * reasonable assumption, given knowing the concept, previous observations no longer influence the later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8550f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The parameters for $P(h)$ and $P(D|h)$\n",
    "\n",
    "For prior $P(H=h), h\\in \\{h_{\\text{two}}, h_{\\text{even}}, h_{\\text{odd}}, h_{\\text{three}}, h_{\\text{all}}, \\ldots\\}$,\n",
    "* due to igorance, we can simply use largely uniform prior over concepts of: square, multiples, powers\n",
    "* but assign higher probability to some common concepts, say $h_{\\text{even}}, h_{\\text{odd}}$\n",
    "* and penalise some very rare concepts, say $h_\\texttt{powers of 2+\\{37\\}}$, $h_\\texttt{powers of 2-\\{32\\}}$\n",
    "\n",
    "We use a uniform distributed likelihood for $P(d_i|h)$: $$P(d_i|h) = \\begin{cases}\\left[\\frac{1}{\\text{size}(h)}\\right], & \\text{if}\\; d_i \\in h \\\\ 0 & \\text{otherwise}\\end{cases}$$\n",
    "\n",
    "* $\\text{size}(h)$ is the size of qualifying set of the concept\n",
    "  * e.g. $h_{\\text{even}} = \\{2,4,6,\\ldots, 100\\}$, $\\text{size}(h_{\\text{even}}) = 50$\n",
    "  * $h_{\\text{end in 9}} = \\{9,19,29,\\ldots, 99\\}$, $\\text{size}(h_{\\text{even}}) = 10$\n",
    "* therefore, $$P(\\{16\\}|h_{\\text{even}}) = 1/50, P(\\{16\\}|h_{\\text{power of 4}}) = 1/3, P(\\{16\\}|h_{\\text{end in 9}}) = 0, $$  \n",
    "  $$P(\\{16, 8, 2, 64\\}|h_{\\text{even}}) = (1/50)^4, P(\\{16, 8, 2, 64\\}|h_{\\text{power of 4}}) = 0$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9841f73",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Concept inference by Baye's rule with $\\mathcal{D}=\\{16\\}$\n",
    "\n",
    "Baye's rule: $$P(H|\\mathcal{D}) \\propto \\underbrace{P(H)}_{\\text{prior}} \\underbrace{P(\\mathcal{D}|h)}_{\\text{Likelihood}}$$\n",
    "\n",
    "<center><img src=\"https://leo.host.cs.st-andrews.ac.uk/figs/joshPriorLikPost16.png\" width = \"800\" height=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed221d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Concept inference by Baye's rule with $\\mathcal{D}=\\{16,8,2,4\\}$\n",
    "\n",
    "<center><img src=\"https://leo.host.cs.st-andrews.ac.uk/figs/joshPriorLikPostAll.png\" width = \"800\" height=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c299b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian predictive distribution (not examinable)\n",
    "\n",
    "We also want to predict future observations:\n",
    "\n",
    "$$P(d_{N+1} |\\mathcal{D})$$\n",
    "\n",
    "* conditional on the observation so far, the posterior distribution over a future observation $d_{N+1}$\n",
    "\n",
    "\n",
    "Use the two rules: sum and chain rule\n",
    "\n",
    "$$P(d_{N+1} |\\mathcal{D}) = \\sum_{h} P(d_{N+1},h|\\mathcal{D}) = \\sum_{h} P(d_{N+1}|h,\\mathcal{D})P(h|\\mathcal{D})$$\n",
    "\n",
    "We further apply conditional independent assumption\n",
    "\n",
    "$$P(d_{N+1}|h,\\mathcal{D}) = P(d_{N+1}|h)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ee33a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Combined the above we have \n",
    "\n",
    "$$P(d_{N+1} |\\mathcal{D}) = \\sum_{h} P(d_{N+1}|h)P(h|\\mathcal{D})$$\n",
    "\n",
    "* a weighted average over $P(d_{N+1}|h)$\n",
    "* weights are $P(h|\\mathcal{D})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed5f85",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian predictive distribution on $\\mathcal{D}=\\{16\\}$\n",
    "\n",
    "<center><img src=\"https://leo.host.cs.st-andrews.ac.uk/figs/joshPredictive16.png\" width = \"1200\" height=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998322d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Machine's prediction on concept learning based on Bayesian inference\n",
    "\n",
    "Compare with human's prediction (left), machine's prediction (right) is pretty much indistinguishable !\n",
    "\n",
    "Human's prediction         |  Machine's prediction \n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://leo.host.cs.st-andrews.ac.uk/figs/josh-5-5.png)  |  ![](https://leo.host.cs.st-andrews.ac.uk/figs/josh-5-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de36e424",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "* Using joint probability distribution\n",
    "  * contains all the information we need \n",
    "  * but not practical: too many parameters\n",
    "  \n",
    "* Conditional independence\n",
    "  * simplifies the joint distribution\n",
    "   $P(\\mathcal{D}|H=h) = \\prod P(d|H=h)$ \n",
    "  \n",
    "* Inference is inverse engineering\n",
    "  * specify the distribution (generating process): by using chain rule and CI assumption\n",
    "  $$P(\\mathcal{D},H) = P(H) P(\\mathcal{D}|H)$$\n",
    "  * inference is doing the reverse engineering: given the observation what are the unknowns (by Baye's rule)\n",
    "  $$P(H=h|\\mathcal{D})\\propto P(H=h) P(\\mathcal{D}|H=h)$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}